{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemented crewai to create 3 agents as mentioned in the problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Part is same as the basic_rag part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMport crewai librarier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import PDFSearchTool\n",
    "from crewai_tools import tools\n",
    "from crewai import Crew , Task , Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sm4th/.local/lib/python3.10/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_deepseek import ChatDeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the embedding and chat llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =  OpenAIEmbeddings(\n",
    "        api_key = 'api_key',\n",
    "        model=\"text-embedding-3-small\" ,\n",
    ")\n",
    "\n",
    "openai_llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key='api_key',\n",
    "    timeout=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Information_Agent = Agent(\n",
    "    role = 'Information Extractor',\n",
    "    goal = 'Extract key entities, facts, and relationships from document text',\n",
    "    backstory=(\n",
    "        \"You are an expert at extracting entities , facts and relationship between them from the given text\"\n",
    "        \"Give your output in JSON format so that another agent can understand it\"\n",
    "    ),\n",
    "    verbose = True,\n",
    "    allow_delegation = False ,\n",
    "    llm= openai_llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthesis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Synthesis_Agent = Agent(\n",
    "    role='summarizer',\n",
    "    goal ='Summarize and organize extracted information',\n",
    "    backstory = (\n",
    "        \"You are an expert at summarizing and organising information\"\n",
    "        \"Use the entities , facts , relationship , etc given to you to summarize and organize them\"\n",
    "        \"Provide a clean and concise answer\"\n",
    "        \"Provide your Output in JSON format\"\n",
    "    ),\n",
    "    verbose = True,\n",
    "    allow_delegation = False,\n",
    "    llm = openai_llm\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Handling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query_agent = Agent(\n",
    "    role = 'query handling',\n",
    "    goal = 'Handle natural language questions about processed documents',\n",
    "    backstory = (\n",
    "        \"you are an expert at answering queries regarding processed document with help of a summarised and organised text \"\n",
    "        \"your should be proper and concise\"\n",
    "        \"make sure answer is relavent to the question\"\n",
    "    ),\n",
    "    verbose = True,\n",
    "    allow_delegation = False,\n",
    "    llm = openai_llm,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Task for the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "information_task = Task(\n",
    "    description = (\"Analyse the provided text : {text}\"\n",
    "                   \"Based on the text extract entities , facts and relationships\"\n",
    "                   \"return a clean and concise answer retaining important features of the text\"\n",
    "    ),\n",
    "    expected_output = (\"Give a JSON formatted file with Entities  , Facts and Relationships\"),\n",
    "    agent = Information_Agent\n",
    ")\n",
    "\n",
    "\n",
    "summarize_task = Task(\n",
    "    description = (\"Based on the response from the information task summarize and organize the information provided\"\n",
    "                   \"make the answer clean and concise\"\n",
    "    ),\n",
    "    expected_output = (\"Give a JSON formatted file with summarized and organized text\"),\n",
    "    agent = Synthesis_Agent,\n",
    "    context = [information_task],\n",
    ")\n",
    "\n",
    "query_task = Task(\n",
    "    description = (\"Based on the response from the summarize task and the question  generate a answer relavent to the question and information\"\n",
    "                   \"make the answer proper and concise\"\n",
    "    ),\n",
    "    expected_output = (\"Answer in english for the question user asked\"),\n",
    "    agent = Query_agent,\n",
    "    context = [summarize_task],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising a crew of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_crew = Crew(\n",
    "    agents = [Information_Agent, Synthesis_Agent, Query_agent],\n",
    "    tasks = [information_task, summarize_task, query_task],\n",
    "    verbose =True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">╭──────────────────────────────────────────── Crew Execution Started ─────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">045f94b4-d928-4663-9b23-4da97db4d86c</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">│</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">│</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m╭─\u001b[0m\u001b[36m───────────────────────────────────────────\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m────────────────────────────────────────────\u001b[0m\u001b[36m─╮\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m045f94b4-d928-4663-9b23-4da97db4d86c\u001b[0m                                                                       \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m│\u001b[0m                                                                                                                 \u001b[36m│\u001b[0m\n",
       "\u001b[36m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\"># Agent:</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Information Extractor</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;95m# Agent:\u001b[0m \u001b[1;92mInformation Extractor\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">## Task:</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Analyse the provided text : As LLMs continue to push technological boundaries, KV Caches have proven to be</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">indispensable in ensuring inference efficiency and scalability.Based on the text extract entities , facts and </span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">relationshipsreturn a clean and concise answer retaining important features of the text</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[95m## Task:\u001b[0m \u001b[92mAnalyse the provided text : As LLMs continue to push technological boundaries, KV Caches have proven to be\u001b[0m\n",
       "\u001b[92mindispensable in ensuring inference efficiency and scalability.Based on the text extract entities , facts and \u001b[0m\n",
       "\u001b[92mrelationshipsreturn a clean and concise answer retaining important features of the text\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a1ec6b8e2243bf96cd8e65c242c001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = {\"text\" : \"As LLMs continue to push technological boundaries, KV Caches have proven to be indispensable in ensuring inference efficiency and scalability.\" }\n",
    "       # just example text\n",
    "results = rag_crew.kickoff(inputs=inputs)       \n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
