{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rY2FyCAVO347"
   },
   "source": [
    "Q2 image classification using resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzSeIfDV-_6U"
   },
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hc_UAJxA_Bym"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #to plot validation loss curves\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf  #i have used tf as the main ml framework\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqdKi__M_ZYU"
   },
   "source": [
    "Loading mnist data into pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJzw3Qbp_aAc"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('fashion-mnist_train.csv')\n",
    "test_df = pd.read_csv('fashion-mnist_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jf9rtva_scg"
   },
   "source": [
    "preparing data : 1. Normalising the pixel value between 0,1 from 0,255 - for easier computation\n",
    "\n",
    "2. Converting the category labels to encodings using to_categorical function as to categorical_crossentropy function to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VTeie4g_hkL"
   },
   "outputs": [],
   "source": [
    "X = train_df.drop('label', axis=1).values / 255.0  # normalizes to [0, 1] as pixel values is bw 0 , 255\n",
    "y = to_categorical(train_df['label'].values, num_classes=10) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ79QgRSFAvh"
   },
   "source": [
    "Splitting the training dataset into training and validation set 90-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sadiG_e3FGqu"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jBgTbcyFmE0"
   },
   "source": [
    "Preprocessing the image data : Reshaping flat 784 array to 28x28x1 (1 for as grayscale)\n",
    "\n",
    "Converting grayscale to rgb using duplication (grayscale_to_rgb function) for resnet\n",
    "\n",
    "Resizing to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "br-29sVeFddx"
   },
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.reshape(image, [28, 28, 1])\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHGRhO6PF3kg"
   },
   "source": [
    "Making a tf.data pipeline as its easy to use and allows parellel processing in batches\n",
    "\n",
    "-from_tensor_slices converts numpy arrays to tf.data objects\n",
    "- map function applies the preprocess function on these objects\n",
    "- that AUTOTUNE stuff is basically for tf to decide how do to the parellel processing (how many thread to use and stuff)\n",
    "-shuffle is for randomising in each epoch\n",
    "- prefetch is for preloading the next batch while the current is on training (for gpu utilisation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhVJKZoxF8Xo"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE =  100\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3hD8aZpK5gy"
   },
   "source": [
    "Creating a Sequential model using keras , will add layers in this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwoaQoOxGKez"
   },
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skqMBbO9LCvg"
   },
   "source": [
    "Loading the Resnet50 Model from keras without the top layer.\n",
    "\n",
    "this model has weights pretrained from imagenet dataset\n",
    "\n",
    "defining the input size and the no. of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K74BHiwHGK24",
    "outputId": "b988664e-7a59-4013-ffb3-c7d1d65ee870"
   },
   "outputs": [],
   "source": [
    "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
    "                   input_shape=(224,224,3),\n",
    "                   pooling='avg',classes=10,\n",
    "                   weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3fQ4QdfMFaU"
   },
   "source": [
    "Freezing the backbone, setting model layers as untrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqAFiiJDGMG9"
   },
   "outputs": [],
   "source": [
    "for layer in pretrained_model.layers:\n",
    "        layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QR89TgwgQLcO"
   },
   "source": [
    "Adding the layers resnet model --> Linear block ----> FC layer  ---> Output layer (softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maSBY-huMNaM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "aUiEXuMgGNwk",
    "outputId": "821f37fb-3414-4b85-9864-9e58cbb573c8"
   },
   "outputs": [],
   "source": [
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPgBLFcCM7kj"
   },
   "source": [
    "compiling the model with Adam as optimizer and loss function method as categorical_crossentropy as we have many classes\n",
    "\n",
    "\n",
    "Fitting the model for validation set with 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZjY53GqGQNp",
    "outputId": "4893a9a4-5a9c-42fe-f10f-69d024aa2a5e"
   },
   "outputs": [],
   "source": [
    "resnet_model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "epochs=10\n",
    "\n",
    "history = resnet_model.fit(train_dataset, validation_data=val_dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf0HhGkJNTR5"
   },
   "source": [
    "plotting the Training/Validation Accuracy and Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "48GtNcNsGXbg",
    "outputId": "ec8a9246-cbed-45e7-d049-4ed3c2f0ae07"
   },
   "outputs": [],
   "source": [
    "fig1 = plt.gcf()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.axis(ymin=0.4,ymax=1)\n",
    "plt.grid()\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3n07oPLGkS_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cr6I9pmmNrKp"
   },
   "source": [
    "***Fine-Tuning***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuQLPOFINxzL"
   },
   "source": [
    "Unfreezing the last 10 layers of the model for training and again compiler and fitting the model on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytfRmY-6OHjm"
   },
   "source": [
    "Also i set the learning rate lower this time  = 10^-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rp_GmV9FN5qF"
   },
   "outputs": [],
   "source": [
    "for layer in pretrained_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "resnet_model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = resnet_model.fit(train_dataset, validation_data=val_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeVRj8pVODUz"
   },
   "source": [
    "plotting the Training/Validation Accuracy and Loss curves after fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6m04U_FzOSTA"
   },
   "outputs": [],
   "source": [
    "fig1 = plt.gcf()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.axis(ymin=0.4,ymax=1)\n",
    "plt.grid()\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9X5BXbXCOUtH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8UYzSZtOZEr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ajnTNB7OZZb"
   },
   "source": [
    "Finally Predicting the Test dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjEtIfYfOesD"
   },
   "outputs": [],
   "source": [
    "loss , accuracy = resnet_model.evaluate(test_dataset)\n",
    "print(f\"Accuracy : {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
